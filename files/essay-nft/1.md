# Proof of Personhood and the Race for Identity

- **Writer name:** Alex LaBossiere
- **Writer address:** 0x000000000000000000000000000000000000000A
- **Original publication date:** 2022-07-27
- **Original publication URL:** https://labossiere.substack.com/p/proof-of-personhood-and-the-race

_This is winning essay #1 from the 4-week 1729 Writers Cohort #2. [1729 Writers](https://paper.li/1729writers) is a collective that writes about ideas related to Balaji Srinivasan’s new book [The Network State](https://thenetworkstate.com)._

---

Identity is embedded in the human experience. Over the course of history, we’ve given ourselves names, monikers and pseudonyms to identify, describe and collaborate with one another. The advent of the internet didn’t change the importance of this, but instead shifted the dynamic: suddenly we could all interact with each other at any time from anywhere in the world. Digital identity became more exposed, and inevitably more important than the names we carried around with us in day-to-day life.

In the beginning, things were simple. The early days of the internet prompted us to spin up pseudonyms in chat rooms, taking on new identities as we went and trusting that whatever was on the other side of that chatbox or email was a living, breathing human. We couldn’t actually converse with machines, so judging the sentience of anything online was as straightforward a task as any.

Eventually came the rise of today’s tech giants, who sought to implement real-name policies on their users. In a way, this was logical; more of our social lives were rapidly moving online, and ensuring you were interacting with a real person had real influence on your own day-to-day activity. This resultant social infrastructure was built on trust in each other’s identities and allowed us to coordinate ourselves at scale, but came with a massive side effect.

The fact of the matter is that the rise of today’s tech giants took on a greater role than simply forming platforms and networked infrastructure for large-scale human interaction. In doing all of this, they also became credential providers, taking on a function traditionally reserved for the nation state in its indexing of names and issuance of identifiers like social security numbers. Accessing online spaces meant signing in with Google, Facebook or an email, all of which mediated your access every step of the way. Paula Berman and Divya Siddarth put it well:

“If the “State is the monopoly on violence,” as Max Weber once defined it, then the surveillance state (or surveillance capital) is the monopoly on identity.”

As the centralization of identity comes to a head, we’re seeing a new paradigm of infrastructure being built on top of the internet, that promises to change this. Cryptonetworks better facilitate mass human coordination through incentive mechanisms enabled by blockchains. Functionally, these usually rely on a consensus mechanism like proof-of-stake or proof-of-work to govern and maintain themselves. To keep things simple, we can look at them like identity solutions that grant governance power over a network.

This in mind, they’re quite flawed. Proof-of-stake in a system like Ethereum works out to look more like one-dollar-one-vote, and Bitcoin’s proof-of-work system grants governance to whoever has the most computing power. For technologies designed to democratize the internet, they generally end up concentrating power at scale. .01% of Bitcoin wallets control almost one third of supply, for instance. As more of our lives move online, it’s important to identify the flaws in these decentralized systems and work to build better solutions on top of them.

Assuming the broad digitalization of our social and work lives continues, ensuring that the entity you’re interacting with online is human becomes much more important. I interviewed Renée DiResta in May, and she spoke to the issue succinctly:

“I do think there is something at the same time, a very interesting thing that's happening with emerging tech like generative text AI, where you are very soon not really going to know if you're engaging with a human or not, right? That technology is going to become increasingly more sophisticated. And so this idea of like, proof of person is something that's been intriguing me lately. What does it mean to have a verified identity? Not who you are specifically, but that you are real. That you exist… I do think that that's one of the more interesting questions or how we're going to reckon with this over the next five or six years.”

It seems a real name policy just isn’t going to cut it anymore.

Liveness
Until very recently in time, computers haven’t come very close to convincing us they’re real people. The idea, though, has been around for some time: the Turing Test was famously put forward in 1950 as a means of measuring a computer’s ability to exhibit behavior indistinguishable from that of a human. to turn this on its head, we might consider a computer’s ability to determine whether or not you’re a real person. Dorothy E. Denning took things in this direction by coining the term “liveness” in a 2001 study. In essence, liveness refers to a computer’s ability to determine whether or not it’s interfacing with a physically present human being.

In a modern day context, liveness takes precedence. For a while now, we’ve relied on CAPTCHAs and other primitive solutions to determine liveness and keep the internet relatively bot-free. Today though, they’re reaching their limit’s end.

To combat this in more security-reliant contexts, liveness detection systems have been put in place. FaceID on your iPhone, for example, can be thought of as such a system. Simply speaking, a liveness detection just determines if a computer is interacting with a real, breathing human being.

FaceTec, a leader in liveness detection, divides attack vectors on into 5 levels of increasing sophistication, ranging from more obviously fake high-resolution masks and “puppets” to injecting previously recorded or doctored video into live camera feeds, rendering liveness practically impossible to determine.

Sybil attack levels by FaceTec. Source: Humanode.io via Liveness.com
As it turns out, there isn’t a great level of skill needed to accomplish any of this. White Ushanka is a Russian Youtuber who spends their time demonstrating free and low-cost methods of fooling liveness detection systems. Oftentimes, their methods are shockingly simple. Here’s another example of people spoofing a liveness detection system, this time painting over a picture of someone’s eyes to simulate blinking and gaining access to their bank accounts.

Even if you don’t have the financial means to buy ultra-realistic masks or the technical sophistication to inject pre-recorded video into a camera feed, tools are readily accessible for you. Solutions in the form of live deepfake masks and voice filters mean more and more people can take on new, plausible and digitally mediated identities. Even real-time rendered avatars like the ones Meta teased last fall are becoming tough to distinguish from reality.

The implications at play here are non-trivial: Just last year, a group of hackers beat a liveness detection system run by the Chinese Government to fake tax invoices. To do this, they rendered a number of deepfake “puppets” out of photos of individuals they collected online (only a level 1 attack, according to FaceTec). To the liveness detection systems the criminals fooled, these were legitimate requests by authorized users for tax invoices they were entitled to. Ultimately, they made off with over $75M.

Advances in AI can make things even more complicated. The forward leaps natural language processing has made in recent years has allowed us to create stunningly lifelike images of people from simple text prompts. You can even generate fake faces on-demand at www.this-person-does-not-exist.com

These people aren’t real. Left photo generated from a descriptive text prompt on DALLE-2, Via Patrick Clair. Right photo generated on www.thispersondoesnotexist.com.
We can even have almost-natural conversations with autoregressive language models like OpenAI’s GPT-3. LaMDA, a similar system Google is working on, even fooled an engineer into thinking it’s sentient (spoiler: it’s not). The point here is that it’s becoming increasingly difficult to tell real from fake. If this continues unchecked, things might get out of control quite quickly.

The ultimate solution here likely lies in Proof of Personhood: robust systems to ensure that you’re a real human being.

Proof-of-Personhood
One person making a million accounts on Facebook doesn’t do much to Facebook’s operations or bottom line— in fact, Facebook has over 200 million of them. On the other hand, distributed systems and peer-to-peer networks are often plagued by duplicate identities that try to take control of them.

These are called Sybil attacks, and target these kinds of networks because they can’t take any action without reaching consensus. At the same time, the expectation is that each human user only has one account or identity. In the absence of a means of proving unique personhood, today’s largest peer-to-peer networks work around this by requiring proof of work or stake in a network for control over it. This doesn’t eliminate duplicate identities, but makes Sybil attacks incredibly costly to attempt.

Proof-of-Personhood is a more direct means of resisting attacks that use multiple fake identities like Sybil attacks. To get more nuanced, we can divide Proof-of-Personhood into two distinct camps: Proof-of-Existence and Proof-of-Uniqueness. The former proves you’re a living, breathing human and the latter proves— crucially— that there’s only one of you.

The core concept at play in Proof-of-Personhood is the removal of objective markers of identity like name or age, and replacing them with subjective inputs like vouching and interpreting. We can break down the approaches to creating Sybil-resistant Proof-of-Personhood systems into 5 camps:

In-Person Events: Originally proposed by Borge et al, pseudonymous parties take place for people to meet and verify each other’s presence. The gatherings themselves take place at the same time in random locations to ensure no one person can be in two or more places at once. The main drawback here is straightforward: it’s ridiculously inconvenient. In addition, it can be difficult to prevent collusion within groups with absolute certainty.

Social Networks: This solution relies on users forming a social network, where each individual verifies and attests to the identity and liveness of others. Again, this solution isn’t airtight, as there’s no verifiably secure method of ensuring no small-scale collusion is taking place. Sybil nodes can vouch for other sybil nodes without detection until they reach a detectable mass.

Online Turing Tests: Expanding on CAPTCHAs, online Turing tests rely on users interacting one-on-one, presumably over video, to verify each others’ liveness. As discussed earlier, main weaknesses to this approach include the increasing ease with which we can fool each other of what’s real. Not to mention, it isn’t terribly convenient.

Strong Identities: Proof-of-Personhood can also be attained by relying on a trusted third party to verify individuals’ identities, then anonymize and store that data, on which future interactions can be compared against. The main drawbacks here are the single point of failure even an encrypted database presents, reliance on individuals’ compliancy to opt into the system, and the eventual centralization of trust and complete reliance this kind of solution would create.

Crypto-Biometrics: As a more fleshed-out version of strong identities, crypto-biometrics rely on the use of homomorphic encryption and zero-knowledge proofs to encrypt users’ data such that it never leaves their personal device in the first place. Instead, a ciphertext is used to mediate identity on a network.

It’s important to note that almost all of these solutions are flawed in one way or another. If not by technical feasibility, they aren’t completely airtight, and leave us sure-but-not-totally sure of any given individual’s personhood. In this, we discover degrees of personhood. Since we can never be totally sure one way or another, we end up operating with a confidence interval of someone’s existence and uniqueness. Presumably, there might be a future where a system or network needs a certain level of confidence in you to grant you ownership or governance in it.

Ok, but why does any of this matter in the first place? Aside from security against fooling ourselves and breaking into each other’s phones, there’s 3 main use-cases robust Proof-of-Personhood protocols enable:

Resistance to Centralization: As mentioned earlier on, proof-of-work and proof-of-stake consensus mechanisms in peer-to-peer networks are great at making Sybil attacks costly, but lack any real resistance to centralization. Besides keeping a vast minority from accumulating majority ownership in a network, Proof-of-Personhood ensures power isn’t inevitably centralized.

True Online Democracy: In the same vein, proving one’s existence and uniqueness leads to true online democracy. For the first time, consensus mechanisms that create one-dollar-one-vote and one-CPU-one-vote systems can become secure, one-person-one-vote systems.

Universal Basic Income: In further applying this concept, the ability to apply Proof-of-Personhood at scale gives us the ability to provide instantly and permissionlessly distributed universal basic income within a network.

The Race for Identity
As more of our lives move online, ensuring that the entity you’re interacting with online is human becomes crucial. Regardless of which systems end up becoming ubiquitous, a greater assurance of personhood online means we can more completely leverage the internet to support any number of aspects of the many facets of our own lives. Consolidating trust means richer experiences in digital spaces.

The big question here as we zoom back out is the unavoidable conflict we’re presented with: proving our uniqueness and existence online is in a race with advances in AI and deepfakes, which can be used us trick us and the systems we built to shield ourselves. If Proof-of-Humanity doesn’t win out, we might find ourselves facing a much larger problem. The point in time where we can no longer tell real from fake is the point in time society’s increasingly digitalized social and economic processes could begin to break down.

Thanks for reading,

Alex

Type your email…
Subscribe
Sources:

A minuscule .01% of Bitcoin holders control nearly a third of the supply by Marco Quiroz-Gutierrez

An Internet for Humans: Proof-of-Personhood Explained by Paula Berman and Divya Siddarth

Attack on Sybil by cyber_preacher

Biometric Liveness Detection Explained - Liveness.com

Chinese government-run facial recognition system hacked by tax fraudsters by Masha Borak

Fraudsters deepfake CEO’s voice to trick manager into transferring $243,000 by Ravie Lakshmanan

Google fires Blake Lemoine, the engineer who claimed AI chatbot is a person by Jon Brokdin

How Facebook’s real-name policy changed social media forever by Jeff Kosseff

LaBossiere Podcast #38 - Renée DiResta

On Collusion by Vitalik Buterin

Proof of personhood - Wikipedia

Sam Altman’s Worldcoin wants to scan eyeballs in exchange for crypto by Lucas Matney

The 3 things an AI must demonstrate to be considered sentient by Tristan Greene

The Turing test: AI still hasn’t passed the “imitation game” by Stephen Johnson

Thinking (creatively) with the help of machines by Sarah Guo

What Is Homomorphic Encryption? And Why Is It So Transformative? by Bernard Marr

Why CAPTCHAs Have Gotten so Difficult by Josh Dzieza

Worldcoin by Jake
